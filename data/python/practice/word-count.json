{
  "language": "python",
  "type": "practice",
  "slug": "word-count",
  "title": "Word Count",
  "docs": {
    "instructions": "# Instructions\r\n\r\nYour task is to count how many times each word occurs in a subtitle of a drama.\r\n\r\nThe subtitles from these dramas use only ASCII characters.\r\n\r\nThe characters often speak in casual English, using contractions like _they're_ or _it's_.\r\nThough these contractions come from two words (e.g. _we are_), the contraction (_we're_) is considered a single word.\r\n\r\nWords can be separated by any form of punctuation (e.g. \":\", \"!\", or \"?\") or whitespace (e.g. \"\\t\", \"\\n\", or \" \").\r\nThe only punctuation that does not separate words is the apostrophe in contractions.\r\n\r\nNumbers are considered words.\r\nIf the subtitles say _It costs 100 dollars._ then _100_ will be its own word.\r\n\r\nWords are case insensitive.\r\nFor example, the word _you_ occurs three times in the following sentence:\r\n\r\n> You come back, you hear me? DO YOU HEAR ME?\r\n\r\nThe ordering of the word counts in the results doesn't matter.\r\n\r\nHere's an example that incorporates several of the elements discussed above:\r\n\r\n- simple words\r\n- contractions\r\n- numbers\r\n- case insensitive words\r\n- punctuation (including apostrophes) to separate words\r\n- different forms of whitespace to separate words\r\n\r\n`\"That's the password: 'PASSWORD 123'!\", cried the Special Agent.\\nSo I fled.`\r\n\r\nThe mapping for this subtitle would be:\r\n\r\n```text\r\n123: 1\r\nagent: 1\r\ncried: 1\r\nfled: 1\r\ni: 1\r\npassword: 2\r\nso: 1\r\nspecial: 1\r\nthat's: 1\r\nthe: 2\r\n```\r\n",
    "hints": "# Hints\r\n\r\n## General\r\n\r\nThis exercise has many potential solutions and many paths you can take along the way.\r\nNo path is manifestly \"better\" than another, although a particular path may be more interesting or better suited to what you want to learn or explore right now.\r\nSome paths may trade speed for clarity, others might take up more memory but be more scalable or maintainable.\r\nWe encourage you to try out more than one strategy to see what happens.\r\n\r\n_______\r\n-  Python has a robust set of tools to work with strings. [`str.split`][str.split] [`str.replace`][str.replace] [`str.lower`][str.lower] and [`str.strip`][str.strip] can be particularly helpful with this challenge.\r\n-  String methods can be chained together (_as long as the method returns a `str`_))\r\n-  While `str.split()` is very _specific_, `str.strip()` behaves differently, and allows multiple combinations.\r\n-  The [`string`][string] module (as opposed to `str`) has some constants that can be useful for filtering and comparison when processing strings.\r\n________\r\n\r\n-  [Dictionaries][dict] can be helpful for tabulating when items (keys) appear more than once in a string.\r\n-  [`dict.setdefault()`][dict.setdefault] can help in processing when a key might be missing from a dictionary.\r\n-  The [Collections][collections] module implements some really useful subtypes to the core `dict` (dictionary), purpose-built to do things like [tally][collections.counter].\r\n________\r\n-  Exploring the [`re`][re] module and regular expressions can be fun, but is by no means necessary to solve this challenge.\r\n-  [Regex101][regex101] is very helpful for experimenting with regular expression logic.\r\n-  Both [`re.sub`][re.sub] and [`re.findall`][re.findall] can be interesting strategies to employ.\r\n________\r\n-  [Comprehensions][comprehensions] can often \"flatten\" loops where items are being appended to a list or inserted into a dictionary.\r\n-  [Generator expressions][generator expressions] can often \"stand in\" for a list comprehension when an iterable is needed.\r\n  Generator expressions are evaluated in a \"lazy\" fashion, and take up less space in memory than a corresponding list comprehension.\r\n\r\n\r\n[collections.counter]: https://docs.python.org/3/library/collections.html#collections.Counter\r\n[collections]: https://docs.python.org/3/library/collections.html#module-collections\r\n[comprehensions]: https://treyhunner.com/2015/12/python-list-comprehensions-now-in-color/\r\n[dict.setdefault]: https://docs.python.org/3/library/stdtypes.html#dict.setdefault\r\n[dict]: https://docs.python.org/3/library/stdtypes.html#mapping-types-dict\r\n[generator expressions]: https://dbader.org/blog/python-generator-expressions\r\n[re.findall]: https://docs.python.org/3/library/re.html?highlight=re#re.findall\r\n[re.sub]: https://docs.python.org/3/library/re.html?highlight=re#re.sub\r\n[re]: https://docs.python.org/3/library/re.html?highlight=re#module-re\r\n[regex101]: https://regex101.com/\r\n[str.lower]: https://docs.python.org/3/library/stdtypes.html#str.lower\r\n[str.replace]: https://docs.python.org/3/library/stdtypes.html#str.replace\r\n[str.split]: https://docs.python.org/3/library/stdtypes.html#str.split\r\n[str.strip]: https://docs.python.org/3/library/stdtypes.html#str.strip\r\n[string]: https://docs.python.org/3/library/string.html\r\n"
  },
  "starter_code": "def count_words(sentence):\r\n    pass\r\n",
  "tests": "# These tests are auto-generated with test data from:\r\n# https://github.com/exercism/problem-specifications/tree/main/exercises/word-count/canonical-data.json\r\n# File last updated on 2023-07-19\r\n\r\nimport unittest\r\n\r\nfrom word_count import (\r\n    count_words,\r\n)\r\n\r\n\r\nclass WordCountTest(unittest.TestCase):\r\n    def test_count_one_word(self):\r\n        self.assertEqual(count_words(\"word\"), {\"word\": 1})\r\n\r\n    def test_count_one_of_each_word(self):\r\n        self.assertEqual(count_words(\"one of each\"), {\"one\": 1, \"of\": 1, \"each\": 1})\r\n\r\n    def test_multiple_occurrences_of_a_word(self):\r\n        self.assertEqual(\r\n            count_words(\"one fish two fish red fish blue fish\"),\r\n            {\"one\": 1, \"fish\": 4, \"two\": 1, \"red\": 1, \"blue\": 1},\r\n        )\r\n\r\n    def test_handles_cramped_lists(self):\r\n        self.assertEqual(count_words(\"one,two,three\"), {\"one\": 1, \"two\": 1, \"three\": 1})\r\n\r\n    def test_handles_expanded_lists(self):\r\n        self.assertEqual(\r\n            count_words(\"one,\\ntwo,\\nthree\"), {\"one\": 1, \"two\": 1, \"three\": 1}\r\n        )\r\n\r\n    def test_ignore_punctuation(self):\r\n        self.assertEqual(\r\n            count_words(\"car: carpet as java: javascript!!&@$%^&\"),\r\n            {\"car\": 1, \"carpet\": 1, \"as\": 1, \"java\": 1, \"javascript\": 1},\r\n        )\r\n\r\n    def test_include_numbers(self):\r\n        self.assertEqual(\r\n            count_words(\"testing, 1, 2 testing\"), {\"testing\": 2, \"1\": 1, \"2\": 1}\r\n        )\r\n\r\n    def test_normalize_case(self):\r\n        self.assertEqual(count_words(\"go Go GO Stop stop\"), {\"go\": 3, \"stop\": 2})\r\n\r\n    def test_with_apostrophes(self):\r\n        self.assertEqual(\r\n            count_words(\"'First: don't laugh. Then: don't cry. You're getting it.'\"),\r\n            {\r\n                \"first\": 1,\r\n                \"don't\": 2,\r\n                \"laugh\": 1,\r\n                \"then\": 1,\r\n                \"cry\": 1,\r\n                \"you're\": 1,\r\n                \"getting\": 1,\r\n                \"it\": 1,\r\n            },\r\n        )\r\n\r\n    def test_with_quotations(self):\r\n        self.assertEqual(\r\n            count_words(\"Joe can't tell between 'large' and large.\"),\r\n            {\"joe\": 1, \"can't\": 1, \"tell\": 1, \"between\": 1, \"large\": 2, \"and\": 1},\r\n        )\r\n\r\n    def test_substrings_from_the_beginning(self):\r\n        self.assertEqual(\r\n            count_words(\"Joe can't tell between app, apple and a.\"),\r\n            {\r\n                \"joe\": 1,\r\n                \"can't\": 1,\r\n                \"tell\": 1,\r\n                \"between\": 1,\r\n                \"app\": 1,\r\n                \"apple\": 1,\r\n                \"and\": 1,\r\n                \"a\": 1,\r\n            },\r\n        )\r\n\r\n    def test_multiple_spaces_not_detected_as_a_word(self):\r\n        self.assertEqual(\r\n            count_words(\" multiple   whitespaces\"), {\"multiple\": 1, \"whitespaces\": 1}\r\n        )\r\n\r\n    def test_alternating_word_separators_not_detected_as_a_word(self):\r\n        self.assertEqual(\r\n            count_words(\",\\n,one,\\n ,two \\n 'three'\"), {\"one\": 1, \"two\": 1, \"three\": 1}\r\n        )\r\n\r\n    def test_quotation_for_word_with_apostrophe(self):\r\n        self.assertEqual(count_words(\"can, can't, 'can't'\"), {\"can\": 1, \"can't\": 2})\r\n\r\n    # Additional tests for this track\r\n\r\n    def test_tabs(self):\r\n        self.assertEqual(\r\n            count_words(\r\n                \"rah rah ah ah ah\troma roma ma\tga ga oh la la\twant your bad romance\"\r\n            ),\r\n            {\r\n                \"rah\": 2,\r\n                \"ah\": 3,\r\n                \"roma\": 2,\r\n                \"ma\": 1,\r\n                \"ga\": 2,\r\n                \"oh\": 1,\r\n                \"la\": 2,\r\n                \"want\": 1,\r\n                \"your\": 1,\r\n                \"bad\": 1,\r\n                \"romance\": 1,\r\n            },\r\n        )\r\n\r\n    def test_non_alphanumeric(self):\r\n        self.assertEqual(\r\n            count_words(\"hey,my_spacebar_is_broken\"),\r\n            {\"hey\": 1, \"my\": 1, \"spacebar\": 1, \"is\": 1, \"broken\": 1},\r\n        )\r\n\r\n    def test_multiple_apostrophes_ignored(self):\r\n        self.assertEqual(count_words(\"''hey''\"), {\"hey\": 1})\r\n"
}