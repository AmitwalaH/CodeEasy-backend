{
  "concept": "little-sisters-vocab",
  "docs": {
    "introduction": "# Introduction\r\n\r\nA `str` in Python is an [immutable sequence][text sequence] of [Unicode code points][unicode code points].\r\nThese could include letters, diacritical marks, positioning characters, numbers, currency symbols, emoji, punctuation, space and line break characters, and more.\r\n Being immutable, a `str` object's value in memory doesn't change; methods that appear to modify a string return a new copy or instance of that `str` object.\r\n\r\n\r\nA `str` literal can be declared via single `'` or double `\"` quotes. The escape `\\` character is available as needed.\r\n\r\n\r\n```python\r\n\r\n>>> single_quoted = 'These allow \"double quoting\" without \"escape\" characters.'\r\n\r\n>>> double_quoted = \"These allow embedded 'single quoting', so you don't have to use an 'escape' character\".\r\n\r\n>>> escapes = 'If needed, a \\'slash\\' can be used as an escape character within a string when switching quote styles won\\'t work.'\r\n```\r\n\r\nMulti-line strings are declared with `'''` or `\"\"\"`.\r\n\r\n\r\n```python\r\n>>> triple_quoted =  '''Three single quotes or \"double quotes\" in a row allow for multi-line string literals.\r\n  Line break characters, tabs and other whitespace are fully supported.\r\n\r\n  You\\'ll most often encounter these as \"doc strings\" or \"doc tests\" written just below the first line of a function or class definition.\r\n    They\\'re often used with auto documentation ‚úç tools.\r\n    '''\r\n```\r\n\r\nStrings can be concatenated using the `+` operator.\r\n This method should be used sparingly, as it is not very performant or easily maintained.\r\n\r\n\r\n```python\r\nlanguage = \"Ukrainian\"\r\nnumber = \"nine\"\r\nword = \"–¥–µ–≤'—è—Ç—å\"\r\n\r\nsentence = word + \" \" + \"means\" + \" \" + number + \" in \" + language + \".\"\r\n\r\n>>> print(sentence)\r\n...\r\n\"–¥–µ–≤'—è—Ç—å means nine in Ukrainian.\"\r\n```\r\n\r\nIf a `list`, `tuple`, `set` or other collection of individual strings needs to be combined into a single `str`, [`<str>.join(<iterable>)`][str-join], is a better option:\r\n\r\n\r\n```python\r\n# str.join() makes a new string from the iterables elements.\r\n>>> chickens = [\"hen\", \"egg\", \"rooster\"] # Lists are iterable.\r\n>>> ' '.join(chickens)\r\n'hen egg rooster'\r\n\r\n# Any string can be used as the joining element.\r\n>>> ' :: '.join(chickens)\r\n'hen :: egg :: rooster'\r\n\r\n>>> ' üåø '.join(chickens)\r\n'hen üåø egg üåø rooster'\r\n\r\n\r\n# Any iterable can be used as input.\r\n>>> flowers = (\"rose\", \"daisy\", \"carnation\")  # Tuples are iterable.\r\n>>> '*-*'.join(flowers)\r\n'rose*-*daisy*-*carnation'\r\n\r\n>>> flowers = {\"rose\", \"daisy\", \"carnation\"}  # Sets are iterable, but output order is not guaranteed.\r\n>>> '*-*'.join(flowers)\r\n'rose*-*carnation*-*daisy'\r\n\r\n>>> phrase = \"This is my string\"  # Strings are iterable, but be careful!\r\n>>> '..'.join(phrase)\r\n'T..h..i..s.. ..i..s.. ..m..y.. ..s..t..r..i..n..g'\r\n\r\n\r\n# Separators are inserted **between** elements, but can be any string (including spaces).\r\n# This can be exploited for interesting effects.\r\n>>> under_words = ['under', 'current', 'sea', 'pin', 'dog', 'lay']\r\n>>> separator = ' ‚§¥Ô∏è under'\r\n>>> separator.join(under_words)\r\n'under ‚§¥Ô∏è undercurrent ‚§¥Ô∏è undersea ‚§¥Ô∏è underpin ‚§¥Ô∏è underdog ‚§¥Ô∏è underlay'\r\n\r\n# The separator can be composed different ways, as long as the result is a string.\r\n>>> upper_words = ['upper', 'crust', 'case', 'classmen', 'most', 'cut']\r\n>>> separator = ' üåü ' + upper_words[0]\r\n>>> separator.join(upper_words)\r\n 'upper üåü uppercrust üåü uppercase üåü upperclassmen üåü uppermost üåü uppercut'\r\n```\r\n\r\nCode points within a `str` can be referenced by `0-based index` number from the left:\r\n\r\n\r\n```python\r\ncreative = 'Ï∞ΩÏùòÏ†ÅÏù∏'\r\n\r\n>>> creative[0]\r\n'Ï∞Ω'\r\n\r\n>>> creative[2]\r\n'Ï†Å'\r\n\r\n>>> creative[3]\r\n'Ïù∏'\r\n```\r\n\r\nIndexing also works from the right, starting with a `-1-based index`:\r\n\r\n\r\n```python\r\ncreative = 'Ï∞ΩÏùòÏ†ÅÏù∏'\r\n\r\n>>> creative[-4]\r\n'Ï∞Ω'\r\n\r\n>>> creative[-2]\r\n'Ï†Å'\r\n\r\n>>> creative[-1]\r\n'Ïù∏'\r\n\r\n```\r\n\r\nThere is no separate ‚Äúcharacter‚Äù or \"rune\" type in Python, so indexing a string produces a new `str` of length 1:\r\n\r\n\r\n```python\r\n\r\n>>> website = \"exercism\"\r\n>>> type(website[0])\r\n<class 'str'>\r\n\r\n>>> len(website[0])\r\n1\r\n\r\n>>> website[0] == website[0:1] == 'e'\r\nTrue\r\n```\r\n\r\nSubstrings can be selected via _slice notation_, using [`<str>[<start>:stop:<step>]`][common sequence operations] to produce a new string.\r\n Results exclude the `stop` index.\r\n If no `start` is given, the starting index will be 0.\r\n If no `stop` is given, the `stop` index will be the end of the string.\r\n\r\n\r\n```python\r\nmoon_and_stars = 'üåüüåüüåôüåüüåü‚≠ê'\r\nsun_and_moon = 'üåûüåôüåûüåôüåûüåôüåûüåôüåû'\r\n\r\n>>> moon_and_stars[1:4]\r\n'üåüüåôüåü'\r\n\r\n>>> moon_and_stars[:3]\r\n'üåüüåüüåô'\r\n\r\n>>> moon_and_stars[3:]\r\n'üåüüåü‚≠ê'\r\n\r\n>>> moon_and_stars[:-1]\r\n'üåüüåüüåôüåüüåü'\r\n\r\n>>> moon_and_stars[:-3]\r\n'üåüüåüüåô'\r\n\r\n>>> sun_and_moon[::2]\r\n'üåûüåûüåûüåûüåû'\r\n\r\n>>> sun_and_moon[:-2:2]\r\n'üåûüåûüåûüåû'\r\n\r\n>>> sun_and_moon[1:-1:2]\r\n'üåôüåôüåôüåô'\r\n```\r\n\r\nStrings can also be broken into smaller strings via [`<str>.split(<separator>)`][str-split], which will return a `list` of substrings.\r\n The list can then be further indexed or split, if needed.\r\n Using `<str>.split()` without any arguments will split the string on whitespace.\r\n\r\n\r\n```python\r\n>>> cat_ipsum = \"Destroy house in 5 seconds mock the hooman.\"\r\n>>> cat_ipsum.split()\r\n...\r\n['Destroy', 'house', 'in', '5', 'seconds', 'mock', 'the', 'hooman.']\r\n\r\n\r\n>>> cat_ipsum.split()[-1]\r\n'hooman.'\r\n\r\n\r\n>>> cat_words = \"feline, four-footed, ferocious, furry\"\r\n>>> cat_words.split(', ')\r\n...\r\n['feline', 'four-footed', 'ferocious', 'furry']\r\n```\r\n\r\nSeparators for `<str>.split()` can be more than one character.\r\nThe **whole string** is used for split matching.\r\n\r\n\r\n```python\r\n\r\n>>> colors = \"\"\"red,\r\norange,\r\ngreen,\r\npurple,\r\nyellow\"\"\"\r\n\r\n>>> colors.split(',\\n')\r\n['red', 'orange', 'green', 'purple', 'yellow']\r\n```\r\n\r\nStrings support all [common sequence operations][common sequence operations].\r\n Individual code points can be iterated through in a loop via `for item in <str>`.\r\n Indexes _with_ items can be iterated through in a loop via `for index, item in enumerate(<str>)`.\r\n\r\n\r\n```python\r\n\r\n>>> exercise = '·Äú·Ä±·Ä∑·ÄÄ·Äª·ÄÑ·Ä∫·Ä∑'\r\n\r\n# Note that there are more code points than perceived glyphs or characters\r\n>>> for code_point in exercise:\r\n...    print(code_point)\r\n...\r\n·Äú\r\n·Ä±\r\n·Ä∑\r\n·ÄÄ\r\n·Äª\r\n·ÄÑ\r\n·Ä∫\r\n·Ä∑\r\n\r\n# Using enumerate will give both the value and index position of each element.\r\n>>> for index, code_point in enumerate(exercise):\r\n...    print(index, \": \", code_point)\r\n...\r\n0 :  ·Äú\r\n1 :  ·Ä±\r\n2 :  ·Ä∑\r\n3 :  ·ÄÄ\r\n4 :  ·Äª\r\n5 :  ·ÄÑ\r\n6 :  ·Ä∫\r\n7 :  ·Ä∑\r\n```\r\n\r\n\r\n[common sequence operations]: https://docs.python.org/3/library/stdtypes.html#common-sequence-operations\r\n[str-join]: https://docs.python.org/3/library/stdtypes.html#str.join\r\n[str-split]: https://docs.python.org/3/library/stdtypes.html#str.split\r\n[text sequence]: https://docs.python.org/3/library/stdtypes.html#text-sequence-type-str\r\n[unicode code points]: https://stackoverflow.com/questions/27331819/whats-the-difference-between-a-character-a-code-point-a-glyph-and-a-grapheme\r\n",
    "hints": "# Hints\r\n\r\n## General\r\n\r\n- The Python Docs [Tutorial for strings][python-str-doc] has an overview of the Python `str` type.\r\n- String methods [`str.join()`][str-join] and [`str.split()`][str-split] ar very helpful when processing strings.\r\n- The Python Docs on [Sequence Types][common sequence operations] has a rundown of operations common to all sequences, including `strings`, `lists`, `tuples`, and `ranges`.\r\n\r\nThere's four activities in the assignment, each with a set of text or words to work with.\r\n\r\n## 1. Add a prefix to a word\r\n\r\n- Small strings can be concatenated with the `+` operator.\r\n\r\n## 2. Add prefixes to word groups\r\n\r\n- Believe it or not, [`str.join()`][str-join] is all you need here.  **A loop is not required**.\r\n- The tests will be feeding your function a `list`.  There will be no need to alter this `list` if you can figure out a good delimiter string.\r\n- Remember that delimiter strings go between elements and \"glue\" them together into a single string. Delimiters are inserted _without_ space, although you can include space characters within them.\r\n- Like [`str.split()`][str-split], `str.join()` can process an arbitrary-length string, made up of any unicode code points. _Unlike_ `str.split()`, it can also process arbitrary-length iterables like `list`, `tuple`, and `set`.\r\n\r\n\r\n## 3. Remove a suffix from a word\r\n\r\n- Strings can be indexed or sliced from either the left (starting at 0) or the right (starting at -1).\r\n- If you want the last code point of an arbitrary-length string, you can use [-1].\r\n- The last three letters in a string can be \"sliced off\" using a negative index. e.g. 'beautiful'[:-3] == 'beauti'\r\n\r\n## 4. Extract and transform a word\r\n\r\n- Using [`str.split()`][str-split] returns a `list` of strings broken on white space.\r\n- `lists` are sequences, and can be indexed.\r\n- [`str.split()`][str-split] can be directly indexed: `'Exercism rocks!'.split()[0] == 'Exercism'`\r\n- Be careful of punctuation! Periods can be removed via slice: `'dark.'[:-1] == 'dark'`\r\n\r\n\r\n[common sequence operations]: https://docs.python.org/3/library/stdtypes.html#text-sequence-type-str\r\n[python-str-doc]: https://docs.python.org/3/tutorial/introduction.html#strings\r\n[str-join]: https://docs.python.org/3/library/stdtypes.html#str.join\r\n[str-split]: https://docs.python.org/3/library/stdtypes.html#str.split\r\n",
    "instructions": "# Instructions\r\n\r\nYou are helping your younger sister with her English vocabulary homework, which she is finding very tedious.\r\n Her class is learning to create new words by adding _prefixes_ and _suffixes_.\r\n Given a set of words, the teacher is looking for correctly transformed words with correct spelling by adding the prefix to the beginning or the suffix to the ending.\r\n\r\nThe assignment has four activities, each with a set of text or words to work with.\r\n\r\n\r\n## 1. Add a prefix to a word\r\n\r\nOne of the most common prefixes in English is `un`, meaning \"not\".\r\n In this activity, your sister needs to make negative, or \"not\" words by adding `un` to them.\r\n\r\nImplement the `add_prefix_un(<word>)` function that takes `word` as a parameter and returns a new `un` prefixed word:\r\n\r\n\r\n```python\r\n>>> add_prefix_un(\"happy\")\r\n'unhappy'\r\n\r\n>>> add_prefix_un(\"manageable\")\r\n'unmanageable'\r\n```\r\n\r\n\r\n## 2. Add prefixes to word groups\r\n\r\nThere are four more common prefixes that your sister's class is studying:\r\n `en` (_meaning to 'put into' or 'cover with'_),\r\n `pre` (_meaning 'before' or 'forward'_),\r\n `auto` (_meaning 'self' or 'same'_),\r\n  and `inter` (_meaning 'between' or 'among'_).\r\n\r\n In this exercise, the class is creating groups of vocabulary words using these prefixes, so they can be studied together.\r\n Each prefix comes in a list with common words it's used with.\r\n The students need to apply the prefix and produce a string that shows the prefix applied to all of the words.\r\n\r\nImplement the `make_word_groups(<vocab_words>)` function that takes a `vocab_words` as a parameter in the following form:\r\n `[<prefix>, <word_1>, <word_2> .... <word_n>]`, and returns a string with the prefix applied to each word that looks like:\r\n  `'<prefix> :: <prefix><word_1> :: <prefix><word_2> :: <prefix><word_n>'`.\r\n\r\nCreating a `for` or `while` loop to process the input is not needed here.\r\nThink carefully about which string methods (and delimiters) you could use instead.\r\n\r\n\r\n```python\r\n>>> make_word_groups(['en', 'close', 'joy', 'lighten'])\r\n'en :: enclose :: enjoy :: enlighten'\r\n\r\n>>> make_word_groups(['pre', 'serve', 'dispose', 'position'])\r\n'pre :: preserve :: predispose :: preposition'\r\n\r\n>> make_word_groups(['auto', 'didactic', 'graph', 'mate'])\r\n'auto :: autodidactic :: autograph :: automate'\r\n\r\n>>> make_word_groups(['inter', 'twine', 'connected', 'dependent'])\r\n'inter :: intertwine :: interconnected :: interdependent'\r\n```\r\n\r\n\r\n## 3. Remove a suffix from a word\r\n\r\n`ness` is a common suffix that means _'state of being'_.\r\n In this activity, your sister needs to find the original root word by removing the `ness` suffix.\r\n  But of course there are pesky spelling rules: If the root word originally ended in a consonant followed by a 'y', then the 'y' was changed to 'i'.\r\n Removing 'ness' needs to restore the 'y' in those root words. e.g. `happiness` --> `happi` --> `happy`.\r\n\r\nImplement the `remove_suffix_ness(<word>)` function that takes in a `word`, and returns the root word without the `ness` suffix.\r\n\r\n\r\n```python\r\n>>> remove_suffix_ness(\"heaviness\")\r\n'heavy'\r\n\r\n>>> remove_suffix_ness(\"sadness\")\r\n'sad'\r\n```\r\n\r\n## 4. Extract and transform a word\r\n\r\nSuffixes are often used to change the part of speech a word is assigned to.\r\n A common practice in English is \"verbing\" or \"verbifying\" -- where an adjective _becomes_ a verb by adding an `en` suffix.\r\n\r\nIn this task, your sister is going to practice \"verbing\" words by extracting an adjective from a sentence and turning it into a verb.\r\n Fortunately, all the words that need to be transformed here are \"regular\" - they don't need spelling changes to add the suffix.\r\n\r\nImplement the `adjective_to_verb(<sentence>, <index>)` function that takes two parameters.\r\n A `sentence` using the vocabulary word, and the `index` of the word, once that sentence is split apart.\r\n The function should return the extracted adjective as a verb.\r\n\r\n\r\n```python\r\n>>> adjective_to_verb('I need to make that bright.', -1 )\r\n'brighten'\r\n\r\n>>> adjective_to_verb('It got dark as the sun set.', 2)\r\n'darken'\r\n```\r\n",
    "design": "# Design\r\n\r\n## Goal\r\n\r\nThe goal of this exercise is to teach the student about Python strings, and familiarize them with string manipulation in Python.\r\n\r\n## Things to teach\r\n\r\n- Know that Python has a `str` type.\r\n- How to use `<str>.join()`\r\n- How to use `<str>.split()`\r\n- Know how to manipulate strings to create new strings.\r\n\r\n## Things not to teach\r\n\r\n- Regex: `regex`.  That is for a different exercise.\r\n- Iteration: Although strings are iterable, this is not the focus of this exercise.\r\n\r\n\r\n## Prerequisites\r\n\r\n- `basics`: The student should be familiar with the basics exercise.\r\n\r\n## Representer\r\n\r\nThis exercise does not require any logic to be added to the [representer][representer]\r\n\r\n## Analyzer\r\n\r\nThis exercise does not require any logic to be added to the [analyzer][analyzer].\r\n\r\n[analyzer]: https://github.com/exercism/python-analyzer\r\n[representer]: https://github.com/exercism/python-representer\r\n"
  },
  "config": {
    "authors": [
      "aldraco",
      "BethanyG"
    ],
    "files": {
      "solution": [
        "strings.py"
      ],
      "test": [
        "strings_test.py"
      ],
      "exemplar": [
        ".meta/exemplar.py"
      ]
    },
    "icon": "two-fer",
    "blurb": "Learn about strings by helping your little sister with her vocabulary homework."
  },
  "starter_code": "\"\"\"Functions for creating, transforming, and adding prefixes to strings.\"\"\"\r\n\r\n\r\ndef add_prefix_un(word):\r\n    \"\"\"Take the given word and add the 'un' prefix.\r\n\r\n    :param word: str - containing the root word.\r\n    :return: str - of root word prepended with 'un'.\r\n    \"\"\"\r\n\r\n    pass\r\n\r\n\r\ndef make_word_groups(vocab_words):\r\n    \"\"\"Transform a list containing a prefix and words into a string with the prefix followed by the words with prefix prepended.\r\n\r\n    :param vocab_words: list - of vocabulary words with prefix in first index.\r\n    :return: str - of prefix followed by vocabulary words with\r\n            prefix applied.\r\n\r\n    This function takes a `vocab_words` list and returns a string\r\n    with the prefix and the words with prefix applied, separated\r\n     by ' :: '.\r\n\r\n    For example: list('en', 'close', 'joy', 'lighten'),\r\n    produces the following string: 'en :: enclose :: enjoy :: enlighten'.\r\n    \"\"\"\r\n\r\n    pass\r\n\r\n\r\ndef remove_suffix_ness(word):\r\n    \"\"\"Remove the suffix from the word while keeping spelling in mind.\r\n\r\n    :param word: str - of word to remove suffix from.\r\n    :return: str - of word with suffix removed & spelling adjusted.\r\n\r\n    For example: \"heaviness\" becomes \"heavy\", but \"sadness\" becomes \"sad\".\r\n    \"\"\"\r\n\r\n    pass\r\n\r\n\r\ndef adjective_to_verb(sentence, index):\r\n    \"\"\"Change the adjective within the sentence to a verb.\r\n\r\n    :param sentence: str - that uses the word in sentence.\r\n    :param index: int - index of the word to remove and transform.\r\n    :return: str - word that changes the extracted adjective to a verb.\r\n\r\n    For example, (\"It got dark as the sun set.\", 2) becomes \"darken\".\r\n    \"\"\"\r\n\r\n    pass\r\n",
  "exemplar_code": "\"\"\"Functions for creating, transforming, and adding prefixes to strings.\"\"\"\r\n\r\n\r\ndef add_prefix_un(word):\r\n    \"\"\"Take the given word and add the 'un' prefix.\r\n\r\n    :param word: str - containing the root word.\r\n    :return: str - of root word prepended with 'un'.\r\n    \"\"\"\r\n\r\n    return 'un' + word\r\n\r\n\r\ndef make_word_groups(vocab_words):\r\n    \"\"\"Transform a list containing a prefix and words into a string with the prefix followed by the words with prefix prepended.\r\n\r\n    :param vocab_words: list - of vocabulary words with prefix in first index.\r\n    :return: str - of prefix followed by vocabulary words with\r\n            prefix applied.\r\n\r\n    This function takes a `vocab_words` list and returns a string\r\n    with the prefix and the words with prefix applied, separated\r\n     by ' :: '.\r\n\r\n    For example: list('en', 'close', 'joy', 'lighten'),\r\n    produces the following string: 'en :: enclose :: enjoy :: enlighten'.\r\n    \"\"\"\r\n\r\n    prefix = vocab_words[0]\r\n    joiner = ' :: ' + prefix\r\n\r\n    return joiner.join(vocab_words)\r\n\r\n\r\ndef remove_suffix_ness(word):\r\n    \"\"\"Remove the suffix from the word while keeping spelling in mind.\r\n\r\n    :param word: str - of word to remove suffix from.\r\n    :return: str - of word with suffix removed & spelling adjusted.\r\n\r\n    For example: \"heaviness\" becomes \"heavy\", but \"sadness\" becomes \"sad\".\r\n    \"\"\"\r\n\r\n    word = word[:-4]\r\n    if word[-1] == 'i':\r\n        word = word[:-1] + 'y'\r\n\r\n    return word\r\n\r\n\r\ndef adjective_to_verb(sentence, index):\r\n    \"\"\"Change the adjective within the sentence to a verb.\r\n\r\n    :param sentence: str - that uses the word in sentence.\r\n    :param index: int - index of the word to remove and transform.\r\n    :return: str - word that changes the extracted adjective to a verb.\r\n\r\n    For example, (\"It got dark as the sun set\", 2) becomes \"darken\".\r\n    \"\"\"\r\n\r\n    word = sentence.split()[index]\r\n\r\n    if word[-1] == '.':\r\n        word = word[:-1] + 'en'\r\n    else:\r\n        word = word + 'en'\r\n\r\n    return word\r\n",
  "tests": "import unittest\r\nimport pytest\r\nfrom strings import (add_prefix_un,\r\n                     make_word_groups,\r\n                     remove_suffix_ness,\r\n                     adjective_to_verb)\r\n\r\n\r\nclass LittleSistersVocabTest(unittest.TestCase):\r\n\r\n    @pytest.mark.task(taskno=1)\r\n    def test_add_prefix_un(self):\r\n        input_data = ['happy', 'manageable', 'fold', 'eaten', 'avoidable', 'usual']\r\n        result_data = [f'un{item}' for item in input_data]\r\n\r\n        for variant, (word, expected) in enumerate(zip(input_data, result_data), start=1):\r\n            with self.subTest(f'variation #{variant}', word=word, expected=expected):\r\n\r\n                actual_result = add_prefix_un(word)\r\n                error_message = (f'Called add_prefix_un(\"{word}\"). '\r\n                                f'The function returned \"{actual_result}\", but the '\r\n                                f'tests expected \"{expected}\" after adding \"un\" as a prefix.')\r\n\r\n                self.assertEqual(actual_result, expected, msg=error_message)\r\n\r\n    @pytest.mark.task(taskno=2)\r\n    def test_make_word_groups_en(self):\r\n        input_data = ['en', 'circle', 'fold', 'close', 'joy', 'lighten', 'tangle', 'able', 'code', 'culture']\r\n        expected = ('en :: encircle :: enfold :: enclose :: enjoy :: enlighten ::'\r\n                       ' entangle :: enable :: encode :: enculture')\r\n\r\n        actual_result = make_word_groups(input_data)\r\n        error_message = (f'Called make_word_groups({input_data}). '\r\n                         f'The function returned \"{actual_result}\", '\r\n                         f'but the tests expected \"{expected}\" for the '\r\n                         'word groups.')\r\n\r\n        self.assertEqual(actual_result, expected, msg=error_message)\r\n\r\n    @pytest.mark.task(taskno=2)\r\n    def test_make_word_groups_pre(self):\r\n        input_data = ['pre', 'serve', 'dispose', 'position', 'requisite', 'digest',\r\n                      'natal', 'addressed', 'adolescent', 'assumption', 'mature', 'compute']\r\n        expected = ('pre :: preserve :: predispose :: preposition :: prerequisite :: '\r\n                    'predigest :: prenatal :: preaddressed :: preadolescent :: preassumption :: '\r\n                    'premature :: precompute')\r\n\r\n        actual_result = make_word_groups(input_data)\r\n        error_message = (f'Called make_word_groups({input_data}). '\r\n                         f'The function returned \"{actual_result}\", '\r\n                         f'but the tests expected \"{expected}\" for the '\r\n                         'word groups.')\r\n\r\n        self.assertEqual(actual_result, expected, msg=error_message)\r\n\r\n    @pytest.mark.task(taskno=2)\r\n    def test_make_word_groups_auto(self):\r\n        input_data = ['auto', 'didactic', 'graph', 'mate', 'chrome', 'centric', 'complete',\r\n                      'echolalia', 'encoder', 'biography']\r\n        expected = ('auto :: autodidactic :: autograph :: automate :: autochrome :: '\r\n                    'autocentric :: autocomplete :: autoecholalia :: autoencoder :: '\r\n                    'autobiography')\r\n\r\n        actual_result = make_word_groups(input_data)\r\n        error_message = (f'Called make_word_groups({input_data}). '\r\n                         f'The function returned \"{actual_result}\", '\r\n                         f'but the tests expected \"{expected}\" for the '\r\n                         'word groups.')\r\n\r\n        self.assertEqual(actual_result, expected, msg=error_message)\r\n\r\n    @pytest.mark.task(taskno=2)\r\n    def test_make_words_groups_inter(self):\r\n        input_data = ['inter', 'twine', 'connected', 'dependent', 'galactic', 'action',\r\n                      'stellar', 'cellular', 'continental', 'axial', 'operative', 'disciplinary']\r\n        expected = ('inter :: intertwine :: interconnected :: interdependent :: '\r\n                    'intergalactic :: interaction :: interstellar :: intercellular :: '\r\n                    'intercontinental :: interaxial :: interoperative :: interdisciplinary')\r\n\r\n        actual_result = make_word_groups(input_data)\r\n        error_message = (f'Called make_word_groups({input_data}). '\r\n                         f'The function returned \"{actual_result}\", '\r\n                         f'but the tests expected \"{expected}\" for the '\r\n                         'word groups.')\r\n\r\n        self.assertEqual(actual_result, expected, msg=error_message)\r\n\r\n    @pytest.mark.task(taskno=3)\r\n    def test_remove_suffix_ness(self):\r\n        input_data = ['heaviness', 'sadness', 'softness', 'crabbiness', 'lightness', 'artiness', 'edginess']\r\n        result_data = ['heavy', 'sad', 'soft', 'crabby', 'light', 'arty', 'edgy']\r\n\r\n        for variant, (word, expected) in enumerate(zip(input_data, result_data), start=1):\r\n            with self.subTest(f'variation #{variant}', word=word, expected=expected):\r\n                actual_result = remove_suffix_ness(word)\r\n                error_message = (f'Called remove_suffix_ness(\"{word}\"). '\r\n                                 f'The function returned \"{actual_result}\", '\r\n                                 f'but the tests expected \"{expected}\" after the '\r\n                                 'suffix was removed.')\r\n\r\n                self.assertEqual(actual_result, expected, msg=error_message)\r\n\r\n    @pytest.mark.task(taskno=4)\r\n    def test_adjective_to_verb(self):\r\n        input_data = ['Look at the bright sky.',\r\n                      'His expression went dark.',\r\n                      'The bread got hard after sitting out.',\r\n                      'The butter got soft in the sun.',\r\n                      'Her eyes were light blue.',\r\n                      'The morning fog made everything damp with mist.',\r\n                      'He cut the fence pickets short by mistake.',\r\n                      'Charles made weak crying noises.',\r\n                      'The black oil got on the white dog.']\r\n        index_data = [-2, -1, 3, 3, -2, -3, 5, 2, 1]\r\n        result_data = ['brighten', 'darken', 'harden', 'soften',\r\n                       'lighten', 'dampen', 'shorten', 'weaken', 'blacken']\r\n\r\n        for variant, (sentence, index, expected) in enumerate(zip(input_data, index_data, result_data), start=1):\r\n            with self.subTest(f'variation #{variant}', sentence=sentence, index=index, expected=expected):\r\n                actual_result = adjective_to_verb(sentence, index)\r\n                error_message = (f'Called adjective_to_verb(\"{sentence}\", {index}). '\r\n                                 f'The function returned \"{actual_result}\", but the tests '\r\n                                 f'expected \"{expected}\" as the verb for '\r\n                                 f'the word at index {index}.')\r\n\r\n                self.assertEqual(actual_result, expected, msg=error_message)\r\n"
}